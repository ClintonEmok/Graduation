---
phase: 06
plan: 03
type: execute
wave: 3
depends_on: [06-02]
files_modified: [src/store/useDataStore.ts, src/hooks/useCrimeStream.ts, src/components/viz/DataPoints.tsx, src/components/viz/Controls.tsx]
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Frontend can fetch data from the streaming API"
    - "Data is stored efficiently (TypedArrays/Columnar) in the store"
    - "Visualization renders points from the new data source"
  artifacts:
    - path: "src/store/useDataStore.ts"
      provides: "State management for real data"
    - path: "src/hooks/useCrimeStream.ts"
      provides: "Logic to consume the Arrow stream"
    - path: "src/components/viz/DataPoints.tsx"
      provides: "Rendering logic adapted for columnar data"
  key_links:
    - from: "src/hooks/useCrimeStream.ts"
      to: "/api/crime/stream"
      via: "fetch and RecordBatchReader"
    - from: "src/components/viz/DataPoints.tsx"
      to: "src/store/useDataStore.ts"
      via: "selector"
---

<objective>
Connect the frontend to the streaming API, consuming the Arrow stream and updating the visualization to render the real data efficiently.

Purpose: Complete the data pipeline from backend to pixels.
Output: Working visualization of the parquet data.
</objective>

<execution_context>
@src/store/useDataStore.ts
@src/components/viz/DataPoints.tsx
</execution_context>

<context>
@.planning/phases/06-data-backend-loading/06-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Stream Consumer Hook</name>
  <files>src/hooks/useCrimeStream.ts</files>
  <action>
    Create a hook `useCrimeStream` that:
    1. Fetches `/api/crime/stream`.
    2. Uses `apache-arrow`'s `RecordBatchReader` to parse the stream.
    3. Yields batches or appends them to a buffer.
  </action>
  <verify>
    Console log the batches in a test component.
  </verify>
  <done>Hook retrieves and parses data.</done>
</task>

<task type="auto">
  <name>Task 2: Update Data Store for Columnar Data</name>
  <files>src/store/useDataStore.ts</files>
  <action>
    Refactor `useDataStore` to support a `realData` mode:
    1. Add `columns: { x: Float32Array, y: Float32Array, z: Float32Array, type: Uint8Array, ... } | null`.
    2. Add action `loadRealData()` that calls the stream hook (or implements the fetch logic directly) and populates `columns`.
    3. Maintain `data: DataPoint[]` for backward compatibility or mock mode, but prioritize `columns` if present.
  </action>
  <verify>
    Call `loadRealData` and check if store updates.
  </verify>
  <done>Store supports columnar data.</done>
</task>

<task type="auto">
  <name>Task 3: Adapt Visualization</name>
  <files>src/components/viz/DataPoints.tsx</files>
  <action>
    Update `DataPoints.tsx` to handle columnar data:
    1. Check if `columns` (from store) is available.
    2. If yes, construct the `instancedBufferAttribute` directly from the `Float32Array` columns (avoiding the loop).
    3. If no, fall back to the existing `data.forEach` logic.
    
    *Note:* This is a critical performance optimization for rendering 100k+ points.
  </action>
  <verify>
    Load real data and verify points appear in the 3D scene without freezing the UI.
  </verify>
  <done>Visualization renders real data efficiently.</done>
</task>

<task type="auto">
  <name>Task 4: Add UI Trigger</name>
  <files>src/components/viz/Controls.tsx</files>
  <action>
    Add a button "Load Real Data" to the Controls/Sidebar.
    Bind it to `loadRealData` action in the store.
  </action>
  <verify>
    Click button -> Data loads.
  </verify>
  <done>User can trigger data load.</done>
</task>

</tasks>

<verification>
- Click "Load Real Data".
- Check network tab for stream response.
- Check 3D view for new points.
</verification>

<success_criteria>
- Real data is fetched from API.
- Data is stored in efficient binary format.
- Visualization renders the points.
</success_criteria>

<output>
After completion, create `.planning/phases/06-data-backend-loading/06-03-SUMMARY.md`
</output>
